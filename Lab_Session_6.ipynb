{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "317c2be0",
   "metadata": {},
   "source": [
    "# Pytorch:-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03623494",
   "metadata": {},
   "source": [
    "Pytorch a Python-based scientific computing package targeted at two sets of audiences:\n",
    "\n",
    "* A replacement for NumPy to use the power of GPUs\n",
    "* a deep learning research platform that provides maximum flexibility and speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3901ae46",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "\n",
    "Tensors are similar to NumPyâ€™s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9205d07b",
   "metadata": {},
   "source": [
    "PyTorch provides functions similar to numpy to create tensors:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72a07cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34428090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 8.5899e+09, 0.0000e+00],\n",
      "        [8.5899e+09, 1.1557e+27, 2.0507e-10]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(2, 3) # Construct a 5x3 matrix, uninitialized\n",
    "print(x)\n",
    "print(x.size()) # torch.Size is a tuple, so it supports all tuple operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c76ab72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6840, 0.6399, 0.2165],\n",
      "        [0.2138, 0.9944, 0.8523]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 3) # Construct a randomly initialized matrix\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "076eaca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long) # Construct a matrix filled zeros and of dtype long\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b686b643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3]) # Construct a tensor directly from data\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad728f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 1.1268, -0.0866,  0.2110],\n",
      "        [-0.5446, -0.7028,  0.9314]])\n"
     ]
    }
   ],
   "source": [
    "# create a tensor based on an existing tensor. These methods will reuse properties of the input tensor, e.g. dtype, unless new values are provided by user\n",
    "x = x.new_ones(2, 3, dtype=torch.double)      # new_* methods take in sizes\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c777afa",
   "metadata": {},
   "source": [
    "Slicing also works the same way as in numpy arrays. See for an example below:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07de1ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2110, 0.9314])\n",
      "tensor([[ 1.1268, -0.0866,  0.2110]])\n",
      "tensor([[0.9314]])\n"
     ]
    }
   ],
   "source": [
    "# Every row, only the last column\n",
    "print(x[:, -1])\n",
    "\n",
    "# First row, all columns\n",
    "print(x[:1, :])\n",
    "\n",
    "# Lower right most corner\n",
    "print(x[-1:, -1:])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e12e67",
   "metadata": {},
   "source": [
    "A slight caveat here is reshape operation, which is a bit different from numpy. It turns out Pytorch decided to come up with a new name that no one else uses, they call it .view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d7719c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1268, -0.0866,  0.2110, -0.5446, -0.7028,  0.9314]])\n"
     ]
    }
   ],
   "source": [
    "y = x.view([1,6])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c2db5d",
   "metadata": {},
   "source": [
    "### Operations:-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23b75bd",
   "metadata": {},
   "source": [
    "There are multiple syntaxes for operations. In the following example, we will take a look at the addition operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "846b62cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.1253,  0.5229,  0.6215],\n",
      "        [-0.2157, -0.6249,  0.9333]])\n",
      "tensor([[ 2.1253,  0.5229,  0.6215],\n",
      "        [-0.2157, -0.6249,  0.9333]])\n",
      "tensor([[ 2.1253,  0.5229,  0.6215],\n",
      "        [-0.2157, -0.6249,  0.9333]])\n",
      "tensor([[ 2.1253,  0.5229,  0.6215],\n",
      "        [-0.2157, -0.6249,  0.9333]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(2, 3)\n",
    "print(x + y)\n",
    "\n",
    "print(torch.add(x, y))\n",
    "\n",
    "result = torch.empty(2, 3)\n",
    "torch.add(x, y, out=result) # Providing an output tensor as argument\n",
    "print(result)\n",
    "\n",
    "y.add_(x) # In-place addition\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5fb328a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4678, -0.7703, -1.1082],\n",
       "        [-0.0742, -0.9053, -0.3361]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cross product\n",
    "t1 = torch.randn(2, 3)\n",
    "t2 = torch.randn(2, 3)\n",
    "t1.cross(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a90c7664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100.],\n",
       "        [250.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute matrix product\n",
    "t = (torch.Tensor([[2, 4], [5, 10]]).mm(torch.Tensor([[10], [20]])))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0af3cbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  4.],\n",
       "        [ 9., 16.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elementwise multiplication\n",
    "t = torch.Tensor([[1, 2], [3, 4]])\n",
    "t.mul(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad84ff25",
   "metadata": {},
   "source": [
    "**Read later:**\n",
    "\n",
    "\n",
    "  100+ Tensor operations, including transposing, indexing,\n",
    "  mathematical operations, linear algebra, random numbers, etc.,\n",
    "  are described here <https://pytorch.org/docs/torch>.\n",
    "\n",
    "### NumPy Bridge\n",
    "\n",
    "Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n",
    "\n",
    "The Torch Tensor and NumPy array will share their underlying memory\n",
    "locations, and changing one will change the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "155fa999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy() # Converts torch tensor to numpy array\n",
    "print(b)\n",
    "\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c9c0af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a) # Converts numpy array to torch tensor\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69566134",
   "metadata": {},
   "source": [
    "### Neural Networks in Pytorch:-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8c945a",
   "metadata": {},
   "source": [
    "The torch.nn import gives us access to some helpful neural network things, such as various neural network layer types (things like regular fully-connected layers, convolutional layers (for imagery), recurrent layers...etc). \n",
    "\n",
    "The torch.nn.functional area specifically gives us access to some handy functions that we might not want to write ourselves. We will be using the relu or \"rectified linear\" activation function for our neurons. Instead of writing all of the code for these things, we can just import them, since these are things everyone will be needing in their deep learning code.\n",
    "\n",
    "For now, in the course we have only spoken about feed forward neural networks, so we will be talking about those:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1952d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4b0a43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net()\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4357954d",
   "metadata": {},
   "source": [
    "You might see above we are using **super** method to inherit from **nn.module** class:-\n",
    "\n",
    "Typically, when you inherit from a parent class, that init method doesn't actually get run. This is how we can run that init method of the parent class, which can sometimes be required...because we actually want to initialize things! For example, let's show some classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c23426d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing b\n"
     ]
    }
   ],
   "source": [
    "class a:\n",
    "    '''Will be a parent class'''\n",
    "    def __init__(self):\n",
    "        print(\"initializing a\")\n",
    "\n",
    "class b(a):\n",
    "    '''Inherits from a, but does not run a's init method '''\n",
    "    def __init__(self):\n",
    "        print(\"initializing b\")\n",
    "\n",
    "class c(a):\n",
    "    '''Inhereits from a, but does run a's init method'''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print(\"initializing c\")\n",
    "\n",
    "b_ob = b()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e41a49e",
   "metadata": {},
   "source": [
    "Notice how our b_ob doesn't have the a class init method run. If we create a c_ob from the c class though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86331c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing a\n",
      "initializing c\n"
     ]
    }
   ],
   "source": [
    "c_ob = c()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f78e71",
   "metadata": {},
   "source": [
    "Now, we will try to learn about how to do a basic neural network in pytorch, so we'll use torchvision here, to load the MNIST dataset, which is a image-based dataset showing handwritten digits from 0-9, and your job is to write a neural network to classify them.\n",
    "\n",
    "This dataset is already scaled and pre-processing has already been done. So we will be focusing on how to build neural network with pytorch\n",
    "\n",
    "MNIST data is an image data with dimension 28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f234ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79962a7bd07d4d44950c20f53d403a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-images-idx3-ubyte.gz to MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e473ff795c45419c67f5c73216f46a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab13d717b2e04471ae3b313bcc98690a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37b35d1d5484946bbd3dde87f9fbeb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saurabhbudholiya/opt/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "train = datasets.MNIST('', train=True, download=True, transform=transforms.Compose([ transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST('', train=False, download=True, transform=transforms.Compose([ transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbf3e51",
   "metadata": {},
   "source": [
    "We usually try to pass the data to neural network in batches, because its very computationally expensive to pass the data at once and train the network, second reason being we want the neural network to generalize the pattern\n",
    "\n",
    "The below is an inbuilt functionality of Pytorch to divide the data into batches given a batch size\n",
    "\n",
    "For traning data, we generally want to randomly shuffle the input data as much as possible to hopefully not have any patterns in the data that might throw the network off.\n",
    "\n",
    "For example, if you fed the machine a bunch of images of zeros, the machine would learn to classify everything as zero. Then you'd start feeding it ones, and the machine would figure out pretty quick to classify everything as ones...and so on. Whenever you stop, the network would probably just classify everything as the last thing you trained on. If you shuffle the data, your network is much more likely to figure out what's what."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2c7344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28f88ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([8, 8, 9, 9, 7, 8, 0, 6, 1, 9])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b12af35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[0][0], data[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2da988c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt #see how handwritten digits look like:-\n",
    "\n",
    "plt.imshow(data[0][0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d29aa2f",
   "metadata": {},
   "source": [
    "Now, let us define our layers and activation functions for our neural network:-\n",
    "    \n",
    "So, our first layer takes in 28x28, because our images are 28x28 images of hand-drawn digits. A basic neural network is going to expect to have a flattened array, so not a 28x28, but instead a 1x784.\n",
    "\n",
    "We need to decide the number of units in hidden layer, which is an hyperparameter to work with. For now, we choose that as 64\n",
    "\n",
    "The final output layer has 10 neurons, because we have 10 classes( digits from **0 to 9**)\n",
    "\n",
    "We use relu activation function and then use softmax at the end to arrive at the final scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "121086fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e8a66acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f479f0",
   "metadata": {},
   "source": [
    "We will have to specify the loss function and our optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f7c7e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eb4741",
   "metadata": {},
   "source": [
    "Let us write code to train the neural network now. A few terminologies:-\n",
    "\n",
    "**Epoch :-** One full pass over the entire data\n",
    "\n",
    "it's important to do a net.zero_grad() for every step, otherwise these gradients will add up for every pass, and then we'll be re-optimizing for previous gradients that we already optimized for.\n",
    "\n",
    "See below, how elegantly the code for training is with Pytorch. You don't have to implement any differentation, nor write any weight update equations:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "017969c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3209, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2359, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0882, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0565, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1774, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    for data in trainset: \n",
    "        X, y = data  # X is the batch of features, y is the batch of targets.\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1,784))  # pass in the reshaped batch (recall they are 28x28 atm)\n",
    "        loss = loss_function(output, y)\n",
    "        loss.backward()  #backpropgation\n",
    "        optimizer.step()  # update weights\n",
    "    print(loss)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcf7307",
   "metadata": {},
   "source": [
    "Let us test our model now:-\n",
    "\n",
    "output will return an array of softmax probabilities, we have to pick the index which has the highest probability and compare that to actual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "68b90c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.907\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1,784))\n",
    "\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d64ef94",
   "metadata": {},
   "source": [
    "The accuracy is pretty good:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b5235154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "580a5051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[0].view(-1,784))[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22569450",
   "metadata": {},
   "source": [
    "**This is just an introduction to Pytorch, as we go along the course...you will learn about training neural networks, and then we will dive to more complicated applications:-**\n",
    "\n",
    "There are plenty of resources online and youtube videos to dive deep into pytorch. Some of them are mentioned below:-\n",
    "\n",
    " https://github.com/jcjohnson/pytorch-examples, <br>\n",
    " https://pytorch.org/tutorials/beginner/pytorch_with_examples.html <br>\n",
    " https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627 <br>\n",
    " https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e08a35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
